% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ng_expose.R
\name{NGOnline}
\alias{NGOnline}
\title{Neural Gas Online Learning}
\usage{
NGOnline(
  X,
  W,
  alpha = 0.5,
  alpha_decay = 0.9^(1/nrow(X)),
  alpha_schedule = NULL,
  lambda = 0.25 * nrow(W),
  lambda_decay = 0.9^(1/nrow(X)),
  lambda_schedule = NULL,
  tol_delBMU = 1,
  tol_delQE = 1,
  max_epochs = -1,
  XLabel = NULL,
  parallel = TRUE,
  verbose = TRUE,
  Xseed = NULL
)
}
\arguments{
\item{X}{a data matrix, one observation per row.}

\item{W}{the number of NG prototypes and their initialization, see \code{\link{NGWInitialization}}.}

\item{alpha}{the starting value of the learning rate used for prototype updates. Optional, default = 0.5.}

\item{alpha_decay}{a multiplicative decay factor applied to \code{alpha} after every iteration. Ex.: alpha(t) = alpha(t-1)*decay.
Optional, default = 0.9^(1/\code{nrow(X)}).}

\item{alpha_schedule}{a named vector to set a custom annealing schedule for alpha instead of the multiplicative decay controlled by \code{alpha} and \code{alpha_decay}. 
\code{names(alpha_schedule)} should be integers defining the epoch \strong{through} which the corresponding elements of the vector are applied. 
Optional; if given, this schedule over-rides any multiplicative annealing specified by \code{alpha} and \code{alpha_decay}.}

\item{lambda}{the starting value of the neighborhood factor for cooperative learning. 
Typical values are 25-50\% of the number of prototypes in the network. Optional, default = 0.25*nrow(W).}

\item{lambda_decay}{a multiplicative decay factor applied to lambda after every learning epoch. Ex.: lambda(t) = lambda(t-1)*decay.
Optional, default = 0.9^(1/nrow(X)).}

\item{lambda_schedule}{a named vector defining an annealing schedule for \code{lambda}, in the same format as \code{alpha_schedule}. 
Mandatory if \code{alpha_schedule} is set.}

\item{tol_delBMU}{tolerance controlling convergence of the learning, see \code{\link{NGConvergence}}. Optional, default = 1.}

\item{tol_delQE}{tolerance controlling convergence of the learning, see \code{\link{NGConvergence}}. Optional, default = 1.}

\item{max_epochs}{tolerance controlling convergence of the learning, see \code{\link{NGConvergence}}. Optional, default = -1.}

\item{parallel}{whether to compute in parallel (recommended, default = TRUE).}

\item{verbose}{whether to print learning history to the console after each epoch. Default = TRUE.}

\item{Xseed}{the seed value controlling the random sampling of X for presentation to the network at each iteration. 
Optional, default = NULL does not set this random seed.}

\item{Xlabel}{optionally, a vector of labels for the data in the rows of X.  These can be of any type (character, factor, numeric) but will be converted to integers internally. 
If given, Xlabel allows reporting additional quality measures during the learning process as described in \code{\link{NGLearnHist}}.}
}
\value{
a list with components: 
\describe{
\item{W}{the learned prototype matrix, one prototype per row}
\item{age}{the age of the network (number of epochs trained). age=max_epochs (if given), otherwise it records the number of epochs required to attain convergence according to the criteria in \code{tol_delBMU} and \code{tol_delQE.}}
\item{alpha_start}{the value of alpha at the beginning of learning (the value of initial lambda given)}
\item{alpha_end}{the value of alpha at the end of learning}
\item{alpha_decay}{the supplied decay factor}
\item{alpha_schedule}{the schedule set in \code{alpha_schedule}, if given}
\item{lambda_start}{the value of lambda at the beginning of learning (the value of initial lambda given)}
\item{lambda_end}{the value of lambda at the end of leanring}
\item{lambda_decay}{the supplied decay factor}
\item{lambda_schedule}{the schedule set in \code{lambda_schedule}, if given}
\item{tol_delBMU}{the supplied value of tol_delBMU}
\item{tol_delQE}{the supplied value of tol_delQE}
\item{max_epochs}{the supplied value of max_epochs}
\item{exec_time}{execution time, in minutes}
\item{LearnHist}{a data frame recording various learning histories, see \code{\link{NGLearnHist}}}
}
}
\description{
Neural Gas Online Learning
}
\details{
Neural gas finds prototypes \code{W} which minimize the following cost function: 
\deqn{\sum_i \sum_j h_{ij} d(x_i, w_j)}{sum_i(sum_j( h_ij x d(x_i,w_j) ))}
where the neighborhood function 
\deqn{h_{ij} = exp(-k_{ij} / \lambda)}{h_ij = exp(-k_ij / lambda)}
and \eqn{k_{ij}}{k_ij} = the rank of \eqn{d(x_i, w_j)}, with respect to all other \eqn{d(x_i, w_k)}.  
Ranks are ascending, and by convention start at 0 (instead of 1). 

Online learning updates the prototypes after presentation of a single datum to the network (one learning iteration). 
The update rule is 
\deqn{w(t+1) = w(t) + \alpha  h_{ij}  (x_i - w_j)}{w(t+1) = w(t) + alpha* h_ij*(x_i - w_j)}
}
